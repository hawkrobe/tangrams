{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.attrs import POS\n",
    "\n",
    "# if missing, run `python -m spacy download en_core_web_lg`\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "from utils.nlp_utils import makeMyPMI, memoize, lemmatize_doc\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import sparse2full\n",
    "\n",
    "sys.path.append('../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & pre-process dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass data through NLP pipeline\n",
    "version_to_use = 'tangramsSequential_collapsed'\n",
    "d_raw = pd.read_csv('../../data/{}.csv'.format(version_to_use))\n",
    "d_raw['text'] = [nlp(text) for text in d_raw['contents']]\n",
    "d_raw['lemmas'] = [lemmatize_doc(parsed_text) for parsed_text in d_raw['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex\n",
    "d = d_raw.set_index(['gameid','intendedName', 'repetitionNum'])\n",
    "mux = pd.MultiIndex.from_product(\n",
    "    [d.index.levels[0], d.index.levels[1], d.index.levels[2]], \n",
    "    names=['gameid','intendedName', 'repetitionNum']\n",
    ")\n",
    "d = d.reindex(mux).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute tf-idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "tangrams_list = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "for name, initial_df in d.query('repetitionNum == 1').groupby('gameid') :\n",
    "    final_df = d.query('repetitionNum == 6 and gameid == \"{}\"'.format(name)).sort_values('intendedName').reset_index()\n",
    "    initial_df = initial_df.sort_values('intendedName').reset_index()\n",
    "\n",
    "    # Handle nans\n",
    "    nan_rows = [i for i in range(initial_df.shape[0]) if pd.isna(initial_df.iloc[i,6])]\n",
    "    nan_insert_rows = [k - lag for (lag, k) in enumerate(nan_rows)]\n",
    "\n",
    "    # get number of matches\n",
    "    docs_dict = Dictionary(doc for doc in initial_df['lemmas'] + final_df['lemmas'] if not np.any(pd.isna(doc)))\n",
    "    docs_corpus = [docs_dict.doc2bow(doc) for doc in initial_df['lemmas'] if not np.any(pd.isna(doc))]\n",
    "    model_tfidf = TfidfModel(docs_corpus, id2word=docs_dict, smartirs='bfn') # note: 'bfn' uses boolean for tf term\n",
    "    docs_tfidf  = model_tfidf[docs_corpus]\n",
    "    docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfidf])\n",
    "    docs_vecs   = np.insert(docs_vecs, nan_insert_rows, np.nan, axis=0)\n",
    "\n",
    "    # map back to df\n",
    "    for i, row in initial_df.iterrows() :\n",
    "        words = [docs_dict[i] for i in range(len(docs_vecs[0,]))]\n",
    "        for j, word in enumerate(words) :\n",
    "            tfidf = docs_vecs[i,j]\n",
    "            match = word in list(final_df.loc[i,]['lemmas'])\n",
    "            rows.append([row['gameid'], row['intendedName'], word, tfidf, match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI_df = pd.DataFrame(rows,\n",
    "    columns = ['gameid', 'intendedName', 'word', 'tf-idf', 'finalRoundMatch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI_df.to_csv('../outputs/PMI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out PMIs & matching rates for all words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../outputs/sequential_matchAndPMI.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['word', 'POS', 'match', 'pmi', 'total'])\n",
    "    for word in wordList :\n",
    "        pmi = 0\n",
    "        match = 0\n",
    "        total = 0\n",
    "        for gameid in gameidList:  \n",
    "            memoizedCounts = {}\n",
    "            for tangram in tangramList:\n",
    "                memoizedCounts = memoize(d, gameid, memoizedCounts)\n",
    "                round1WordList = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "                total = total + 1 if word in round1WordList else total\n",
    "                if word in round1WordList :\n",
    "                    PMI_df = makeMyPMI(d, tangram, \"1\", gameid, memoizedCounts)\n",
    "                    pmi = pmi + PMI_df[PMI_df['word'] == word]['logPMI'].tolist()[0]\n",
    "                    round6WordList = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                    match = (match + 1 if (word in round1WordList and word in round6WordList)\n",
    "                             else match)\n",
    "        writer.writerow([word, POSdict[word], float(match) / float(total), pmi/total, total])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples = 1000\n",
    "\n",
    "#grab words with highestPMI for a given tangram/gameid\n",
    "def highestPMIWords(d, tangram, roundNum, gameid):\n",
    "    allTangramCounts = {}\n",
    "    allTangramCounts['counts'] = getWordCounts(d, gameid, \"1\")\n",
    "    allTangramCounts['numWords'] = float(sum(allTangramCounts[\"counts\"].values()))\n",
    "\n",
    "    PMIdf = (makeMyPMI(d, tangram, roundNum, gameid, allTangramCounts))\n",
    "\n",
    "    # Remove numbers\n",
    "    PMIdf['POS'] = [POSdict[word] for word in PMIdf['word']]\n",
    "\n",
    "    #if PMIdf has words, pull out max values, it is empty return it as is\n",
    "    if len(PMIdf.index) > 0:\n",
    "        PMI_values = PMIdf.logPMI.unique()\n",
    "        maxPMI = PMI_values.max()\n",
    "        PMIdf = PMIdf.loc[PMIdf['logPMI'] == maxPMI]\n",
    "        PMIdfword = PMIdf['word']\n",
    "        return PMIdfword.tolist()\n",
    "    else: \n",
    "        return PMIdf\n",
    "\n",
    "with open('../outputs/PMIbootstrap.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['sampleNum', 'tangram', 'gameid', 'numCandidates', 'match', 'highest'])\n",
    "    for gameid in gameidList :\n",
    "        for tangram in tangramList :\n",
    "            round1Words = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "            if len(round1Words) > 0:\n",
    "                # First, write highest PMI match\n",
    "                highPMIWords = highestPMIWords(d, tangram, \"1\", gameid)\n",
    "                round6Words = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                match = np.mean([1 if word in round6Words else 0 for word in highPMIWords ])\n",
    "                writer.writerow([0, tangram, gameid, len(highPMIWords), match, \"highest\"])\n",
    "\n",
    "                # Next, take a bunch of null samples\n",
    "                for i in range(numSamples) :\n",
    "                    randomWord = np.random.choice(round1Words)\n",
    "                    match = np.mean([1 if randomWord in round6Words else 0])\n",
    "                    writer.writerow([i + 1, tangram, gameid, 1, match, \"null\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
